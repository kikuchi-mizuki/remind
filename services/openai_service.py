import os
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from openai import OpenAI
from models.database import Task

class OpenAIService:
    """OpenAI APIã‚’ä½¿ç”¨ã—ãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.model = "gpt-4o-mini"  # ã¾ãŸã¯ "gpt-4o"

    def generate_schedule_proposal(self, tasks: List[Task], free_times: List[dict] = []) -> str:
        """é¸æŠã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã¨ç©ºãæ™‚é–“ã‹ã‚‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆã‚’ç”Ÿæˆ"""
        if not tasks:
            return "ã‚¿ã‚¹ã‚¯ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        
        # ã‚¿ã‚¹ã‚¯æƒ…å ±ã‚’æ•´ç†
        task_info = []
        total_duration = 0
        for task in tasks:
            task_info.append({
                'name': task.name,
                'duration': task.duration_minutes,
                'repeat': task.repeat
            })
            total_duration += task.duration_minutes
        
        # ç©ºãæ™‚é–“æƒ…å ±ã‚’æ•´å½¢
        free_time_str = ""
        if free_times:
            free_time_str = "\nç©ºãæ™‚é–“ãƒªã‚¹ãƒˆ:\n"
            for ft in free_times:
                start = ft['start'].strftime('%H:%M')
                end = ft['end'].strftime('%H:%M')
                free_time_str += f"- {start}ã€œ{end} ({ft['duration_minutes']}åˆ†)\n"
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        prompt = self._create_schedule_prompt(task_info, total_duration, free_time_str)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯åŠ¹ç‡çš„ãªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã¨ç©ºãæ™‚é–“ã‚’ã‚‚ã¨ã«ã€ç”Ÿç”£æ€§ã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1000,
                temperature=0.7
            )
            return response.choices[0].message.content or ""
        except Exception as e:
            print(f"OpenAI API error: {e}")
            return self._generate_fallback_schedule(tasks) or ""

    def generate_modified_schedule(self, user_id: str, modification: Dict) -> str:
        """ä¿®æ­£ã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç”Ÿæˆ"""
        prompt = f"""
ä»¥ä¸‹ã®ä¿®æ­£è¦æ±‚ã«åŸºã¥ã„ã¦ã€æ–°ã—ã„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆã—ã¦ãã ã•ã„ï¼š

ä¿®æ­£å†…å®¹ï¼š
- ã‚¿ã‚¹ã‚¯å: {modification.get('task_name', '')}
- æ–°ã—ã„æ™‚é–“: {modification.get('new_time', '')}

æ—¢å­˜ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è€ƒæ…®ã—ã¦ã€æœ€é©ãªæ™‚é–“ã«å†é…ç½®ã—ã¦ãã ã•ã„ã€‚
ä»–ã®ã‚¿ã‚¹ã‚¯ã¨ã®é‡è¤‡ã‚’é¿ã‘ã€åŠ¹ç‡çš„ãªé †åºã§é…ç½®ã—ã¦ãã ã•ã„ã€‚

ææ¡ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼š
æ™‚é–“ ã‚¿ã‚¹ã‚¯å (æ‰€è¦æ™‚é–“)
ä¾‹ï¼š
09:00 ç­‹ãƒˆãƒ¬ (20åˆ†)
10:30 è²·ã„ç‰© (30åˆ†)
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«èª¿æ•´ã®å°‚é–€å®¶ã§ã™ã€‚ä¿®æ­£è¦æ±‚ã«åŸºã¥ã„ã¦æœ€é©ãªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=500,
                temperature=0.7
            )
            return response.choices[0].message.content or ""
        except Exception as e:
            print(f"OpenAI API error: {e}")
            return "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¿®æ­£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

    def _create_schedule_prompt(self, task_info: List[Dict], total_duration: int, free_time_str: str = "") -> str:
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆï¼ˆç©ºãæ™‚é–“å¯¾å¿œï¼‰"""
        task_list = "\n".join([
            f"- {task['name']} ({task['duration']}åˆ†)" for task in task_info
        ])
        return f"""
ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’ä»Šæ—¥ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«æœ€é©ã«é…ç½®ã—ã¦ãã ã•ã„ï¼š

ã‚¿ã‚¹ã‚¯ä¸€è¦§ï¼š
{task_list}

ç·æ‰€è¦æ™‚é–“: {total_duration}åˆ†
{free_time_str}

é…ç½®ãƒ«ãƒ¼ãƒ«ï¼š
1. é‡è¦ãƒ»é›†ä¸­ç³»ã®ã‚¿ã‚¹ã‚¯ã¯åˆå‰ä¸­ã«é…ç½®
2. è»½ä½œæ¥­ã¯åˆå¾Œã«é…ç½®
3. å‰å¾Œã®äºˆå®šã«å¹²æ¸‰ã—ãªã„ã‚ˆã†ãƒãƒ¼ã‚¸ãƒ³ã‚’æŒãŸã›ã‚‹
4. åŠ¹ç‡çš„ãªé †åºã§é…ç½®ï¼ˆé–¢é€£ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¯è¿‘ãã«é…ç½®ï¼‰

ç©ºãæ™‚é–“ã‚’è€ƒæ…®ã—ã¦ã€æœ€é©ãªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
"""

    def _generate_fallback_schedule(self, tasks: List[Task]) -> str:
        """OpenAI APIãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"""
        schedule = "ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆ\n\n"
        
        current_time = datetime.now().replace(hour=9, minute=0, second=0, microsecond=0)
        
        for i, task in enumerate(tasks):
            # 30åˆ†ã®ãƒãƒ¼ã‚¸ãƒ³ã‚’è¿½åŠ 
            if i > 0:
                current_time += timedelta(minutes=30)
            
            schedule += f"{current_time.strftime('%H:%M')} {task.name} ({task.duration_minutes}åˆ†)\n"
            
            # ã‚¿ã‚¹ã‚¯æ™‚é–“ã‚’åŠ ç®—
            current_time += timedelta(minutes=task.duration_minutes)
        
        schedule += "\næ‰¿èªã™ã‚‹å ´åˆã¯ã€Œæ‰¿èªã€ã¨è¿”ä¿¡ã—ã¦ãã ã•ã„ã€‚"
        return schedule

    def analyze_task_priority(self, task_name: str, duration: int) -> str:
        """ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆåº¦ã‚’åˆ†æ"""
        prompt = f"""
ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆåº¦ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š

ã‚¿ã‚¹ã‚¯å: {task_name}
æ‰€è¦æ™‚é–“: {duration}åˆ†

å„ªå…ˆåº¦ã®åˆ†é¡ï¼š
- high: é‡è¦ã§ç·Šæ€¥ãªã‚¿ã‚¹ã‚¯
- medium: é‡è¦ã ãŒç·Šæ€¥ã§ã¯ãªã„ã‚¿ã‚¹ã‚¯
- low: é‡è¦ã§ã‚‚ç·Šæ€¥ã§ã‚‚ãªã„ã‚¿ã‚¹ã‚¯

å„ªå…ˆåº¦ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆhigh/medium/lowï¼‰
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯ã‚¿ã‚¹ã‚¯ç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆåº¦ã‚’é©åˆ‡ã«åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=10,
                temperature=0.3
            )
            return (response.choices[0].message.content or "").strip().lower()
        except Exception as e:
            print(f"OpenAI API error: {e}")
            return "medium"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä¸­å„ªå…ˆåº¦

    def suggest_task_optimization(self, tasks: List[Task]) -> str:
        """ã‚¿ã‚¹ã‚¯ã®æœ€é©åŒ–ææ¡ˆã‚’ç”Ÿæˆ"""
        task_list = "\n".join([
            f"- {task.name} ({task.duration_minutes}åˆ†)"
            for task in tasks
        ])
        
        prompt = f"""
ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’åˆ†æã—ã€åŠ¹ç‡åŒ–ã®ææ¡ˆã‚’ã—ã¦ãã ã•ã„ï¼š

ã‚¿ã‚¹ã‚¯ä¸€è¦§ï¼š
{task_list}

ä»¥ä¸‹ã®è¦³ç‚¹ã§ææ¡ˆã—ã¦ãã ã•ã„ï¼š
1. ã‚¿ã‚¹ã‚¯ã®é †åºã®æœ€é©åŒ–
2. æ™‚é–“çŸ­ç¸®ã®å¯èƒ½æ€§
3. ãƒãƒƒãƒå‡¦ç†ã§ãã‚‹ã‚¿ã‚¹ã‚¯
4. å‰Šé™¤ãƒ»å§”è­²ã§ãã‚‹ã‚¿ã‚¹ã‚¯

å…·ä½“çš„ã§å®Ÿè·µçš„ãªææ¡ˆã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯ç”Ÿç”£æ€§å‘ä¸Šã®å°‚é–€å®¶ã§ã™ã€‚ã‚¿ã‚¹ã‚¯ã®åŠ¹ç‡åŒ–ã«ã¤ã„ã¦å…·ä½“çš„ãªææ¡ˆã‚’ã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=500,
                temperature=0.7
            )
            return response.choices[0].message.content or ""
        except Exception as e:
            print(f"OpenAI API error: {e}")
            return "ã‚¿ã‚¹ã‚¯ã®æœ€é©åŒ–ææ¡ˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚" 